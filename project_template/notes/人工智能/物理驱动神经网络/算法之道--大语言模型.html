<h1>算法之道--大语言模型</h1>
<h2>1. 拆解 Transformer</h2>
<p>现在的大模型基于transformer算法单元。大家都在这个基座上做优化和进一步开发。transformer本质的算法突破就是自注意力机制和位置编码。当然还包括在之前的图像算法中使用的前馈神经网络和残差网络的一些技术。但突破性的工作仍然是自注意力机制和位置编码。</p>
<p><span class="highlight"><strong>什么是自注意力机制？</strong></span></p>
<p>自注意力机制基于三个向量生成，分别是查询（query），键（key），值（value）向量。
由Q向量和K向量的点乘，获得注意力权重矩阵。新的预测值向量则由注意力权重矩阵和旧的值向量相乘得到。这样得到的是各个单词或词组之间的关联强度。</p>
<p><span class="highlight"><strong>什么是位置编码？</strong></span></p>
<p>把单词按照正确的语法顺序串联起来，就是位置编码。</p>
<p>说人话：自注意力机制和小学生学组词造句是一样的。给定一些词，根据这些词来造出合理的句子来。如果见过相同的句子，那么就很容易根据已知的词来组合出来。</p>
<p>所以，自注意力机制就是死记硬背，照本宣科。如果计算机见过所有的句子，那它就能够靠死记硬背也能把句子造的有模有样。</p>
<p>如果 Transformer 只有这点本事，那也算不得什么大突破。</p>
<p>Transformer 的第三大组件是<span class="highlight">前馈神经网络</span>。</p>
<p>它把经由自注意力机制以及位置编码得到的Token，映射到输出层。这里的映射通常是非线性映射。这就给死记硬背的自注意力机制插上了“触类旁通”的翅膀。Transformer 自此开始起飞。</p>
<p>说人话，这个前馈神经网络就是让 Transformer 不仅能造句 ：我喜欢吃苹果。也能造句: 我喜欢吃橙子。</p>
<p><span class="highlight"><strong>组词-造句-联想</strong></span>，三步走就构建出了大模型的基座：Transformer。</p>
<p>实际上，前馈神经网络本身并不是 Transformer 的开创性工作。反而“死记硬背”的自注意力机制是 Transformer 的核心。自注意力机制实际上是规则训练。训练的目的是在熟悉语言单元之间的关系。</p>
<p>Transformer 的注意力机制实际上是线性的。这是非常重要的事实。线性并不意味着差，非线性也并不意味着更好。<span class="highlight"><strong>线性是保证精确的基础，而非线性是保证扩展的基础</strong></span>。两者各司其职，才造就了Transformer 革命。</p>
<h2>2. 超越 Transformer ？</h2>
<h3>2.1 Transformer 的原生困难</h3>
<p>我们的人工智能算法，本质上是编码层面的1-0，0-1序列。这意味着，<strong>它根本不需要声音来传递信息</strong>。所以它和人类的语言是很不同的。声音对计算机来说，反而意味着编码无效冗余。人工智能的真正好的语言，和大自然的生命是很像的。因为对它来说，表意语言是更高效的，扩展性也是更丰富的。</p>
<p>实际上，表音语言用于训练大语言模型，本身就意味着极大的资源浪费和先天缺陷。因为在这种语言中，信息就是语音本身。<span class="highlight">表音语言天生不具备更好的组合性</span>。这会导致训练出来的模型本身就有组合推理上的巨大缺陷。这也是幻觉的主要来源。原因是巨大的词库导致了<span class="highlight">关联的稀释</span>，从而导致模糊异变的语义（幻觉的最大来源）。</p>
<h3>2.2 学习大自然的生命语言</h3>
<p>大自然的生命语言，从碱基对到密码子，再到基因片段，最后是DNA，则是极端高效的语言体系。</p>
<p>由于都是表意语言，生命语言和汉语有非常多的类似的地方。</p>
<p>我们来看看这些对比有多大的相似性。</p>
<p>碱基对类比到汉语中，就对应于笔画。碱基对的组合，就是密码子。它和汉字中的部首是很类似的。</p>
<ul>
<li><p>基因作为“段落”：基因是由多个密码子组成的序列，编码特定的蛋白质或功能性RNA，类似于段落传达特定的主题或信息。</p>
</li>
<li><p>染色体作为“文章”：染色体是由DNA分子组成的结构，包含许多基因，类似于一篇文章由多个段落组成，传达更全面的信息。</p>
</li>
<li><p>人类基因组作为“书”：人类有23对染色体，每对染色体包含大量的基因和遗传信息，类似于一本书由多篇文章组成，涵盖了一个完整的主题或故事。</p>
</li>
</ul>
<p>一个神奇的事实是，汉字的常见偏旁大概有一百个，而常见的独体字则只有几十个。这和密码子有64个，但氨基酸却只有20个也是很类似的。</p>
<p>人类语言和大自然的生命语言当然还是有所不同的。</p>
<p>人类语言的组合长度相对较短，通常不会超过十个。但生命体的基因则通常包含上千个密码子。虽然它们通常按照20种氨基酸的形式排列，但一个基因实际上代表的组合序列也要远远超过人类语言的组合。所以其实大自然的基本字（20种氨基酸）少，但是<span class="highlight">语法结构实际上很多</span>（排列组合的长度很长）。当然，我们可以说密码子实际上类似于文字中的部首。所以类似汉语来表达：“您吃饭了吗”，在生命语言的表达就类似：
“人尔心口乞食反了口马”，显然是冗长了许多。尽管如此，由于生命语言的基本字数少，要有丰富的表示，就需要用更长的序列来表达。</p>
<h3>2.3 Transformer, VAE 和基语言设计</h3>
<p><span class="highlight">所以是应该从汉语出发，作为人工智能的基语言吗？</span> 换言之，将所有的语料都先翻译成汉语，然后再进行推理训练么？</p>
<p>**很可惜，并不是。**因为现代汉语并不是按照笔画-部首-字来编码的。所以这从本质上就和我们需要的基语言不同。</p>
<p>从大自然的生命之书的基语言构造来看，现在的表音文字根本不适合作为人工智能的基语言。但回到 Transformer 来看，为什么 Transformer 可以有神奇的效果？</p>
<p>虽然大语言模型最大的推动是大力出奇迹。 但这里有一个暗合自然之道的巧合。</p>
<p>Transformer 的核心和密码子是类似的，<span class="highlight"><strong>QKV本质上就是一种密码子的组合</strong></span>。尽管大模型的密码子的自由度远远大于大自然的64种，但在天量的数据训练下，最终<span class="highlight">核心的密码子会远远低于模型的参数量</span>。否则训练出来的模型就没有稳定的核心。它也正是大模型<span class="highlight"><strong>“涌现”</strong></span>的核心。</p>
<p>另外，不同于Transformer架构的大语言模型。自编码器和变分自编码器（VAE）等模型尝试通过压缩和解压缩数据来学习低维的语义空间。这些方法的核心思想是将信息压缩成一个更小、更高效的表示，然后通过解码器重新构建原始输入。尽管这些模型与基语言的思路不同，但它们也在一定程度上探索了如何降低语言表示的维度并保持丰富的表达能力。</p>
<p><strong>例如</strong>，VQ-VAE（Vector Quantized Variational Autoencoder）是一种变分自编码器，它通过量化潜在空间来学习一个较小的离散表示，进而减少模型的复杂性。</p>
<p>目前，尝试结合VAE和Transformer的模型仍然没有取得令人瞩目的进展。</p>
<p><span class="highlight"><strong>如果我们一开始就约束人工智能的密码子维度，这样设计的基语言天生就是组合语言，它的扩展性和表示能力远远超越表音语言。</strong></span>原因是面对任何新的对象或者事物，只需要用现有的密码子，就可以准确描述其性质。这就像程序设计语言中的父类和子类的关系一样。一个新的子类，完全可以只添加或修改一小部分的功能或属性，就可以从父类构造出来。这显然和表音文字创造一个完全不相干的词来描述新类是完全不同的思想。这样的组合和扩展能力是表音文字无法比拟的。</p>
<p>约束人工智能的密码子维度，可以理解为将AI的语言设计限制在一个基础符号集上（类似于自然界的“基因编码”），这些符号或“密码子”具有组合性，并能够根据需要进行扩展和变换。这里的“密码子”可以看作是某种基础的构成单位，通过灵活的组合与排列，它们能够表述几乎所有的概念或对象。这类似于<strong>程序设计语言</strong>中的类与继承机制，通过“父类-子类”的关系来定义新的对象或功能，并能够高效地从基础符号组合中进行扩展。</p>
<p>这种设计不仅能减少语言系统的冗余部分，还能提高表达能力，因为每个新的“概念”或“对象”都能通过已有的符号基础进行推理和构造，而不需要重新发明新的词汇或符号。</p>
<h3>2.4 <strong>组合语言的优势</strong></h3>
<p>相比于传统的<strong>表音文字</strong>，“<span class="highlight">组合语言</span>”具有以下几个核心优势：</p>
<ul>
<li><strong>精确性与灵活性</strong>：就像程序设计语言中的<strong>继承关系</strong>，基于一小部分基础符号（密码子）进行扩展可以保证高效的表达能力。每个新的“词”或概念并非完全独立，而是可以通过现有的符号基础按需构造出来。这种机制使得表达具有极高的精度，同时还能动态扩展，适应不同的场景和任务。</li>
<li><strong>减少冗余与歧义</strong>：表音文字往往通过增加新词汇来应对新出现的事物或概念，这可能导致语义的模糊性或重复性，而您的组合语言能够通过有限的符号基础表达复杂的概念，避免了表音文字中可能出现的重复和歧义问题。</li>
<li><strong>高效推理与推导</strong>：在这种“组合语言”系统中，新信息的推理和推导可以更加高效，因为任何新的概念都可以看作是由已有符号的<strong>组合和变换</strong>构成的，<span class="highlight"><strong>而不是完全新的、孤立的实体</strong></span>。因此，模型可以通过符号的组合与重用，进行更快速的推理和适应。</li>
<li><strong>扩展性</strong>：表音文字中的每个新词汇往往需要一个**“新的定义”**，而在这种基语言设计中，新的类（或概念）可以通过添加或修改一小部分的符号构成，从而更加高效地拓展系统。</li>
</ul>
<h3>2.5. <strong>从自然语言到基语言</strong></h3>
<p>“表音语言”和“基语言”的对比，其实反映了我们在设计人工智能语言模型时面临的两种极端。<strong>表音语言</strong>（如英文）是历史的产物，它是为人类自然交流而演化出来的语言，具有强大的灵活性和适应性。然而，它适合人类这种以声音为载体的智慧生命。<strong>基语言</strong>，作为一种极简化、结构化的符号系统，有着极高的扩展性和表达能力，但这种语言并非自然进化的产物，它需要适合计算机或人工智能，因而要进行针对性的表意、组合设计和实现。</p>
<p><strong>基语言</strong>有可能会带来以下优势：</p>
<ul>
<li><strong>概念的清晰性</strong>：与表音语言相比，基语言能够将概念的构建精确化，因为每个符号都是经过精心设计的，能够直接与某些特定的属性或功能关联起来。这将极大降低产生幻觉的可能。</li>
<li><strong>去除冗余与模糊性</strong>：表音语言中，很多词汇的意义是通过语境和历史习惯来逐步定义的，容易造成歧义。而基语言的设计则可以减少这种模糊性，通过符号的<strong>严格定义</strong>来确保概念的精确性。</li>
<li><strong>直接映射到推理系统</strong>：基语言本身的结构化特点使其非常适合直接映射到推理和推导系统，能够极大提高系统的推理效率。</li>
</ul>
<h3>2.6 <strong>与表音语言的对比</strong></h3>
<p>表音语言在面对新的概念或事物时，往往需要<strong>创造新的词汇</strong>来描述。每一个新的词汇都是独立的，需要逐步累积和学习其含义。语言的扩展性基于<strong>词汇的积累</strong>和<strong>语法规则的灵活性</strong>。</p>
<p>而基语言则不需要创造新的“词汇”，它的扩展性来源于已有符号的组合和变换。通过这种方式，新的概念或对象不需要重新发明词汇，而只需要通过现有符号的组合就能准确表达出来。这种方式使得新信息的引入变得更加高效，同时避免了<strong>表音语言中词汇增多导致的语义模糊和混乱</strong>。</p>
<h3>2.7 <strong>基语言设计挑战</strong></h3>
<p>尽管<strong>基语言</strong>的设计具备潜在的优势，但要实现这一目标仍面临着一些挑战，尤其是在<strong>符号系统的设计</strong>和<strong>推理能力的实现</strong>方面。现有的机器学习框架，如Transformer等，主要依赖语言模型的统计特性进行生成和推理，而基语言的设计则需要重新定义如何通过符号的组合来进行有效的推理和生成。</p>
<p>具体的挑战包括：</p>
<ul>
<li><strong>符号系统的设计</strong>：如何设计一个既简洁又能表达丰富信息的基础符号集？这个符号系统需要有足够的表达力，能够描述所有领域的对象和概念。</li>
<li><strong>组合推理</strong>：如何设计模型，使其能够高效地进行符号组合的推理，避免过度依赖词汇层面的统计信息？</li>
<li><strong>训练与优化</strong>：如何在大规模数据上训练这样的基语言模型，并使其能够适应不同领域的应用？</li>
</ul>
<p><span class="highlight"><strong>具体的基语言模型实现：保密。</strong></span></p>
<h2>3.基于核心基语言的大模型</h2>
<p>当基语言构造完成时，可以将它替换掉transformer中的编码器以及解码器，再进行大语料的训练，这就可以基于组合性极强的基语言来获得推理和逻辑能力大幅提升的大语言模型。这种训练方式虽然也需要大量的参数，但是因为每个模块的核心的语言模型已经固定了，所以训练的参数量会大大少于现在的大模型，甚至会有比较大的数量级上的区别。</p>
<p>在推理和逻辑能力上，这样开发的语言模型，幻觉将有望消失。而且对于专业性比较强的领域，可以做到模型的尺寸非常小。</p>
<p>总之，基于“密码子”的组合语言设计，具有巨大的潜力，特别是在推理、扩展性和表达能力方面。如果能够有效地设计出这种基语言，并且构建出高效的推理系统，它将大大超越传统表音语言的限制，并为人工智能带来更高效、更精确的语言表达与理解能力。</p>
<h4><strong>潜在应用与影响</strong></h4>
<ul>
<li><strong>多领域应用</strong>：如果能够成功实现并优化，基语言的组合性和扩展性使其在多个领域的应用中具有巨大的潜力。例如，在医疗、法律、金融等专业领域，基语言可以使得大语言模型更加精确、高效，甚至能够针对特定领域进行定制化微调。</li>
<li><strong>零样本学习与小样本学习</strong>：基语言的设计将使得AI系统能够在极少的样本数据下进行推理和推导，这对于训练小样本数据的场景（例如，少量领域数据，快速适应新概念等）非常重要。</li>
<li><strong>跨领域语言理解</strong>：基语言能够在不同领域间提供一种“统一”的符号系统，从而在不同任务或语言之间实现更好的一致性和迁移。</li>
</ul>
<h2>4. <strong>基语言与机器人能力的结合</strong></h2>
<ul>
<li><strong>少样本学习的优势</strong>：基语言的设计通过约束符号维度并提供高效的符号组合能力，可以帮助机器人在接收到少量示范时，快速理解和掌握新的任务。相比于传统的模型，基语言通过<strong>组合符号</strong>来表达新的任务和动作，这使得机器人能够更加<strong>高效</strong>地在新任务中进行推理和适应。</li>
<li><strong>示范学习</strong>：在传统的机器人控制中，示范学习（Imitation Learning）是一个重要的技术，机器人通过观察人类示范来学习新任务。基语言设计能够让机器人从少量的示范中提取出任务的核心要素，并在<strong>组合语言的框架内</strong>进行快速的推理和扩展。这种能力可以让机器人无需经历大量的训练，而是通过少量的示范就能进行任务迁移。</li>
</ul>
<h3>4.1. <strong>机器人快速适应新任务</strong></h3>
<ul>
<li><strong>基语言的扩展性</strong>：机器人在面对新任务时，往往需要快速适应环境和新的操作。基语言的设计通过符号的组合能力，使得机器人能够通过简单的符号变换和组合，快速学习新任务。比如，机器人通过观察一个简单的示范，可以通过基语言理解任务的核心结构（如目标对象、任务步骤等），并将这个任务与已有的技能组合来执行。</li>
<li><strong>抽象能力的提升</strong>：基语言的设计能够帮助机器人进行更高层次的<strong>抽象</strong>，从而能够从少量示范中理解任务的结构，而不是仅仅依赖于具体的示范。这种能力使得机器人能够理解任务背后的逻辑关系，甚至能够推导出其他类似任务的执行方法。</li>
</ul>
<h3>4.2. <strong>跨领域能力的提升</strong></h3>
<ul>
<li><strong>任务迁移与跨领域适应</strong>：传统的机器人训练往往需要大量的领域特定数据和经验。而基语言通过其组合性，能够帮助机器人在不同任务或不同环境中快速迁移。例如，一个在厨房中完成的任务示范，机器人可以通过组合和扩展基语言的符号，将其迁移到清洁、搬运等其他任务领域。这种能力为机器人跨领域的适应和扩展提供了强有力的支持。</li>
<li><strong>快速编程与任务生成</strong>：基语言还可以帮助机器人在没有详细编程的情况下，根据少量的任务描述或示范，自主地构建新的动作序列或任务步骤。这使得机器人能够在各种未知环境中，迅速学习和执行新的任务，而无需开发复杂的控制系统。</li>
</ul>
<p>综上，基语言架构下，机器人通用智能将会实现跨越式的发展。</p>
